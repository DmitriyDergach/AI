{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2 по курсу \"Машинное обучение\".\n",
    "Студент группы М8О-307Б-17 Дергач Дмитрий Константинович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи:\n",
    "Необходимо реализовать алгоритмы машинного обучения. Применить данные алгоритмы на наборы данных, подготовленных в первой лабораторной работе. Провести анализ полученных моделей, вычислить метрики классификатора. Произвести тюнинг параметров в случае необходимости. Сравнить полученные результаты с моделями реализованными в scikit-learn. Аналогично построить метрики классификации. Показать, что полученные модели не переобучились. Также необходимо сделать выводы о применимости данных моделей к вашей задаче.\n",
    "1. ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\n",
    "\n",
    "2. KNN\n",
    "\n",
    "3. ДЕРЕВО РЕШЕНИЙ\n",
    "\n",
    "4. RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решаемая задача\n",
    "Определить проишествия при проведении Олимпийских игр по таким параметрам как количество дисциплин, число стран и количество учавствующих спортсменов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обращение к датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>GamesUrl</th>\n",
       "      <th>Disciplines</th>\n",
       "      <th>DisciplinesList</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Athletes</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Events</th>\n",
       "      <th>City</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summergames</td>\n",
       "      <td>https://www.olympic.org/athens-1896</td>\n",
       "      <td>10</td>\n",
       "      <td>['Athletics', 'Cycling Road', 'Cycling Track',...</td>\n",
       "      <td>Greece</td>\n",
       "      <td>06 Apr - 15 Apr</td>\n",
       "      <td>241.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summergames</td>\n",
       "      <td>https://www.olympic.org/paris-1900</td>\n",
       "      <td>20</td>\n",
       "      <td>['Archery', 'Athletics', 'Basque Pelota', 'Cri...</td>\n",
       "      <td>France</td>\n",
       "      <td>14 May - 28 Oct</td>\n",
       "      <td>997.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summergames</td>\n",
       "      <td>https://www.olympic.org/st-louis-1904</td>\n",
       "      <td>19</td>\n",
       "      <td>['Archery', 'Athletics', 'Basketball', 'Boxing...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>01 Jul - 23 Nov</td>\n",
       "      <td>651.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>St Louis</td>\n",
       "      <td>1904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summergames</td>\n",
       "      <td>https://www.olympic.org/london-1908</td>\n",
       "      <td>25</td>\n",
       "      <td>['Archery', 'Athletics', 'Boxing', 'Cycling Tr...</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>27 Apr - 31 Oct</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>London</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summergames</td>\n",
       "      <td>https://www.olympic.org/stockholm-1912</td>\n",
       "      <td>18</td>\n",
       "      <td>['Athletics', 'Cycling Road', 'Diving', 'Eques...</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>05 May - 27 Jul</td>\n",
       "      <td>2407.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Type                                GamesUrl  Disciplines  \\\n",
       "0  summergames     https://www.olympic.org/athens-1896           10   \n",
       "1  summergames      https://www.olympic.org/paris-1900           20   \n",
       "2  summergames   https://www.olympic.org/st-louis-1904           19   \n",
       "3  summergames     https://www.olympic.org/london-1908           25   \n",
       "4  summergames  https://www.olympic.org/stockholm-1912           18   \n",
       "\n",
       "                                     DisciplinesList  \\\n",
       "0  ['Athletics', 'Cycling Road', 'Cycling Track',...   \n",
       "1  ['Archery', 'Athletics', 'Basque Pelota', 'Cri...   \n",
       "2  ['Archery', 'Athletics', 'Basketball', 'Boxing...   \n",
       "3  ['Archery', 'Athletics', 'Boxing', 'Cycling Tr...   \n",
       "4  ['Athletics', 'Cycling Road', 'Diving', 'Eques...   \n",
       "\n",
       "                    Country             Date  Athletes  Countries  Events  \\\n",
       "0                    Greece  06 Apr - 15 Apr     241.0       14.0    43.0   \n",
       "1                    France  14 May - 28 Oct     997.0       24.0    95.0   \n",
       "2  United States of America  01 Jul - 23 Nov     651.0       12.0    95.0   \n",
       "3             Great Britain  27 Apr - 31 Oct    2008.0       22.0   110.0   \n",
       "4                    Sweden  05 May - 27 Jul    2407.0       28.0   102.0   \n",
       "\n",
       "         City  Year  \n",
       "0     Athens   1896  \n",
       "1      Paris   1900  \n",
       "2   St Louis   1904  \n",
       "3     London   1908  \n",
       "4  Stockholm   1912  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympic = pd.read_csv('/Users/dmitry/MAI/3_year/AI/AI_Lab_2/olympic_hosts.csv')\n",
    "olympic = olympic.dropna()\n",
    "olympic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "X = olympic.groupby([\"Year\"]).agg({ \"Events\": \"first\",\n",
    "                                    \"Athletes\": \"sum\", \n",
    "                                    \"Year\": \"first\",\n",
    "                                    \"Disciplines\": \"first\",\n",
    "                                    \"Countries\": \"first\"\n",
    "})\n",
    "\n",
    "median = (X[\"Athletes\"]).median()\n",
    "Y = (X[\"Athletes\"] <= median).astype(int)\n",
    "\n",
    "del X[\"Athletes\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,stratify=Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mins = np.min(X, axis = 0) \n",
    "    maxs = np.max(X, axis = 0) \n",
    "    rng = maxs - mins \n",
    "    norm_X = 1 - ((maxs - X)/rng) \n",
    "    return norm_X\n",
    "def logistic_func(beta, X):\n",
    "    return 1.0/(1 + np.exp(-np.dot(X, beta.T))) \n",
    "\n",
    "def log_gradient(beta, X, y):\n",
    "    first_calc = logistic_func(beta, X) - y.reshape(X.shape[0], -1) \n",
    "    final_calc = np.dot(first_calc.T, X) \n",
    "    return final_calc \n",
    "\n",
    "def cost_func(beta, X, y): \n",
    "    log_func_v = logistic_func(beta, X) \n",
    "    y = np.squeeze(y) \n",
    "    step1 = y * np.log(log_func_v) \n",
    "    step2 = (1 - y) * np.log(1 - log_func_v) \n",
    "    final = -step1 - step2 \n",
    "    return np.mean(final) \n",
    "\n",
    "def grad_desc(X, y, beta, lr=.01, converge_change=.001): \n",
    "    cost = cost_func(beta, X, y) \n",
    "    change_cost = 1\n",
    "    while(change_cost > converge_change): \n",
    "        old_cost = cost \n",
    "        beta = beta - (lr * log_gradient(beta, X, y)) \n",
    "        cost = cost_func(beta, X, y) \n",
    "        change_cost = old_cost - cost\n",
    "    return beta\n",
    "\n",
    "def pred_values(beta, X): \n",
    "    pred_prob = logistic_func(beta, X) \n",
    "    pred_value = np.where(pred_prob >= .5, 1, 0) \n",
    "    return np.squeeze(pred_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SquareEuclidDistance(a,b):\n",
    "    d = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        d += (a[i] - b[i]) * (a[i] - b[i])\n",
    "    return d\n",
    "\n",
    "def KNN(X_train, Y_train, X_test):\n",
    "    Y_test = np.ones(X_test.shape[0])\n",
    "    for j in range(X_test.shape[0]):\n",
    "        Q = np.zeros(Y_train.max() + 1)\n",
    "        for i in range(X_train.shape[0]):\n",
    "            Q[Y_train[i]] += 1/SquareEuclidDistance(X_test[j,:], X_train[i,:])\n",
    "        Y_test[j] = np.argmax(Q)\n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, predicted_class):\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_prun = 0.1\n",
    "\n",
    "    def fit(self, X, y, random_feature = False):\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y, random_feature)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _best_split(self, X, y,random_feature):\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "        for idx in range(self.n_features_):\n",
    "            if(np.random.randint(0, 11) <= self.feature_prun*10):\n",
    "                continue\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y,random_feature, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(predicted_class=predicted_class)\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y,random_feature)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left,random_feature, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right,random_feature, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(size, Max_depth):\n",
    "    head = [None] * size\n",
    "    for i in range(size):\n",
    "        head[i] = DecisionTreeClassifier(max_depth=Max_depth)\n",
    "    return head\n",
    "def fit(forest, X_train, y_train):\n",
    "    for i in range(len(forest)):\n",
    "        subset = np.zeros(X_train.shape)\n",
    "        labels = np.zeros(y_train.shape).astype(int)\n",
    "        for j in range(X_train.shape[0]):\n",
    "            index = np.random.randint(0, X_train.shape[0])\n",
    "            subset[j] = X_train.values[index]\n",
    "            labels[j] = y_train.values[index]\n",
    "        forest[i].fit(X_train.values, y_train.values)\n",
    "def predict(forest, X):\n",
    "    Q = np.zeros([X.shape[0], 2])\n",
    "    for i in range(len(forest)):\n",
    "        pred = forest[i].predict(X.values)\n",
    "        for j in range(len(pred)):\n",
    "            Q[j, pred[j]] += 1\n",
    "    pred = np.zeros([X.shape[0]])\n",
    "    for i in range(X.shape[0]):\n",
    "        pred[i] = np.argmax(Q[i,:])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Своя\" логистическая регрессия и scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 0.8562753036437247\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "X = normalize(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, Y,stratify=Y, test_size=0.1)\n",
    "beta = np.matrix(np.zeros(X.shape[1]))\n",
    "beta = grad_desc(X_train.values, y_train.values, beta)\n",
    "\n",
    "print(\"train precision: \" + str(precision_score(y_train, pred_values(beta, X_train), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, pred_values(beta, X_test), average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 0.7196078431372549\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"train precision: \" + str(precision_score(y_train, clf.predict(X_train), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, clf.predict(X_test), average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Свой\" KNN и scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 1.0\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"train precision: \" + str(precision_score(y_test, KNN(X_test.values, y_test.values, X_test.values), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, KNN(X_train.values, y_train.values, X_test.values), average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 0.8562753036437247\n",
      "test precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"train precision: \" + str(precision_score(y_train, clf.predict(X_train), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, clf.predict(X_test), average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Свое\" дерево решений и scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 1.0\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "clf.fit(X_train.values, y_train.values)\n",
    "print(\"train precision: \" + str(precision_score(y_train, clf.predict(X_train.values), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, clf.predict(X_test.values), average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 1.0\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"train precision: \" + str(precision_score(y_train, clf.predict(X_train), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, clf.predict(X_test), average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Свой\" random forest и scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 1.0\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForest(10, 4)\n",
    "fit(clf, X_train, y_train)\n",
    "print(\"train precision: \" + str(precision_score(y_train, predict(clf,X_train), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, predict(clf,X_test), average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train precision: 1.0\n",
      "test precision: 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"train precision: \" + str(precision_score(y_train, clf.predict(X_train), average='weighted')))\n",
    "print(\"test precision: \" + str(precision_score(y_test, clf.predict(X_test), average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты\n",
    "Как видно все методы вывели примерно один и тотже результат, объяснить это можно простотой датасета и почти линейной зависимостью факторов (больше людей, больше проишествий). Однако стоить выделить такие моменты, что методы \"логистической регрессии\" и \"KNN\" не переобучились на тестовой выборке и смогли выдать наиболее правдоподобные факторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "В этой лабораторной работе я реализовал 4 базовых метода, применяемых к машинному обучению, и сравнил их эффектинвность с уже реализованными. На наглядном примере удалось (хоть и чуть) увидеть, что разные методы дали разные результаты, что объяняется самим датасетом. Также этот случай наглядно показывает необходимость множество методов обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
